{
  "permissions": {
    "allow": [
      "Bash(docker logs:*)",
      "Bash(docker-compose:*)",
      "Bash(docker ps:*)",
      "Bash(docker exec:*)",
      "Bash(docker cp:*)",
      "Bash(curl -X POST http://localhost:8080/auth/login -H \"Content-Type: application/x-www-form-urlencoded\" -d \"username=admin@careermentor.com&password=admin123\")",
      "Bash(curl:*)",
      "Bash(docker:*)",
      "Bash(netstat:*)",
      "Bash(findstr:*)",
      "Bash(timeout:*)",
      "Bash(git init:*)",
      "Bash(git add:*)",
      "Bash(git check-ignore:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nInitial commit: CareerMentor AI Platform\n\n- Full-stack AI career mentoring platform\n- Local LLM inference using Ollama (CPU/GPU support)\n- RAG implementation with pgvector + BM25 hybrid search\n- Microservices architecture (API, Knowledge, Workers, Frontend)\n- Docker Compose deployment with multiple profiles\n- FastAPI backend with async support\n- Next.js frontend with TypeScript\n- Complete documentation and setup guides\n\nTechnical highlights:\n- Zero-cost local inference vs API-based alternatives\n- Privacy-first: all processing happens locally\n- Production-ready architecture with observability\n- OpenTelemetry, Prometheus, Jaeger integration\n- Horizontal scaling support\n\nArchitecture:\n- PostgreSQL with pgvector for vector search\n- Redis for caching and Celery task queue\n- MinIO for object storage\n- Ollama for local LLM serving\n- LiteLLM proxy for OpenAI-compatible API\nEOF\n)\")",
      "Bash(git commit:*)"
    ],
    "deny": [],
    "ask": []
  }
}