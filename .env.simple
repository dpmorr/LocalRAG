# ==================== Simplified Architecture - Environment Variables ====================

# ==================== Core Configuration ====================

ENVIRONMENT=development

# ==================== Infrastructure ====================

# PostgreSQL
POSTGRES_PASSWORD=dev_password

# MinIO (S3-compatible storage)
MINIO_USER=career_mentor
MINIO_PASSWORD=dev_password

# Grafana
GRAFANA_PASSWORD=admin

# ==================== Service Configuration ====================

# Database (used by all services)
DATABASE_URL=postgresql://career_mentor:dev_password@postgres:5432/career_mentor
DATABASE_POOL_SIZE=20

# Redis (cache + Celery broker)
REDIS_URL=redis://redis:6379
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# S3/MinIO
S3_ENDPOINT=http://minio:9000
S3_ACCESS_KEY=career_mentor
S3_SECRET_KEY=dev_password

# ==================== Service URLs ====================

KNOWLEDGE_SERVICE_URL=http://knowledge-service:8081
INFERENCE_SERVICE_URL=http://inference-service:8000

# ==================== Authentication ====================

JWT_SECRET=dev_jwt_secret_change_in_production_with_strong_random_value
JWT_EXPIRATION_MINUTES=60

# ==================== LLM Models ====================

# Primary inference model
INFERENCE_MODEL=Qwen/Qwen2.5-7B-Instruct
# Alternatives:
#   - Qwen/Qwen2.5-14B-Instruct (needs more VRAM)
#   - meta-llama/Llama-3.1-8B-Instruct
#   - Qwen/Qwen2.5-1.5B-Instruct (CPU fallback)

# vLLM settings
TENSOR_PARALLEL_SIZE=1
GPU_MEMORY_UTILIZATION=0.9
MAX_MODEL_LEN=32768
GPU_COUNT=1

# ==================== Retrieval Configuration ====================

RETRIEVAL_TOP_K=50
RERANK_TOP_K=10
BM25_WEIGHT=0.5
CHUNK_SIZE=512
CHUNK_OVERLAP=64

# ==================== External APIs (Optional) ====================

# LangSmith (tracing/debugging)
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=career-mentor-dev

# Anthropic Claude (fallback for long context)
ANTHROPIC_API_KEY=

# Google Gemini (alternative fallback)
GOOGLE_API_KEY=

# ==================== Feature Flags ====================

ENABLE_WEB_RETRIEVAL=true
ALLOWED_WEB_DOMAINS=wikipedia.org,arxiv.org,github.com,stackoverflow.com

# ==================== Observability ====================

OTLP_ENDPOINT=http://jaeger:4317
LOG_LEVEL=INFO

# ==================== Workers ====================

WORKER_CONCURRENCY=4

# ==================== Frontend ====================

NEXT_PUBLIC_API_URL=http://localhost:8080
NEXT_PUBLIC_WS_URL=ws://localhost:8080
NODE_ENV=development
FRONTEND_TARGET=development
FRONTEND_COMMAND=npm run dev

# ==================== Production Overrides (uncomment as needed) ====================

# For production, use managed services and remove localhost references:
# DATABASE_URL=postgresql://user:pass@rds-endpoint:5432/career_mentor
# REDIS_URL=redis://elasticache-endpoint:6379
# S3_ENDPOINT= (leave empty for AWS S3)
# JWT_SECRET=<strong-random-value>
# INFERENCE_MODEL=Qwen/Qwen2.5-14B-Instruct (larger model for production)
